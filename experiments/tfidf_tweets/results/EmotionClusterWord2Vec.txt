I was working on the Word2Vec Clustering algorithm that we developed during the winter school and ran it through our new tweets datatset and we are getting 77.7% Accuracy  (Benchmark Score) which is really promising.

The Algorithm Walk through,
Stop hash tags given by Wenbo was removed from the raw tweets dataset (No more Pre Processing done)
Word2Vec pretrained vectors from Google News dataset (71k + words) taken
Performed K-Means on it with 14259 cluster centers (avg 5 words per cluster)
Randomly sampled 1000 tweets from each emotion and split it 90:10 (Trian:Test)
Convert all the tweets to vectors by building histograms of clusters over them.
Built a LinearSVC model with "l2" loss and penalty
The results below.
                precision    recall  f1-score   support

      anger       0.74      0.73      0.74       100
       fear       0.64      0.65      0.65       100
        joy       0.63      0.69      0.66       100
       love       0.79      0.73      0.76       100
    sadness       0.87      0.88      0.88       100
   surprise       0.99      0.98      0.98       100

avg / total       0.78      0.78      0.78       600

confusion matrix:
[[73  6  8  2 11  0]
 [10 65 15  9  1  0]
 [ 4 20 69  7  0  0]
 [ 5  5 16 73  1  0]
 [ 6  4  0  1 88  1]
 [ 0  1  1  0  0 98]]

Improvements Possible,
Do pre processing
Take 1M words Word2Vec Vectors
Optimize SVC hyper parameters
Train with all the training data
